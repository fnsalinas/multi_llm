# ğŸš€ ConfiguraciÃ³n de Instancia AWS EC2 para DeepSeek
## Proyecto: Prueba de Concepto con DeepSeek y AWS EC2

---

## **1ï¸âƒ£ Resumen del Proyecto**
Este documento describe la configuraciÃ³n de una instancia **AWS EC2** optimizada para ejecutar el modelo **DeepSeek LLM** en la imagen **Deep Learning Base OSS Nvidia Driver GPU AMI (Ubuntu 22.04)**. Se han seleccionado opciones equilibradas entre **rendimiento y costo** para una **prueba de concepto**.

---

## **2ï¸âƒ£ ConfiguraciÃ³n de la Instancia**
### ğŸ“Œ **Nombre de la instancia**
- `multi_llm_poc1`

### ğŸ“Œ **AMI seleccionada**
- **Deep Learning Base OSS Nvidia Driver GPU AMI (Ubuntu 22.04)**
- **ID AMI:** `ami-095694d8118689b4` (64 bits x86)
- **Fuente:** AWS Marketplace

### ğŸ“Œ **Tipo de instancia**
- **Instancia:** `c6i.large`
  - **2 vCPUs**
  - **8 GB RAM**
  - **Optimizado para computaciÃ³n**
  - **Costo aprox.:** `$0.177 USD/hora` (on-demand)

---

## **3ï¸âƒ£ ConfiguraciÃ³n de Seguridad y Red**
### ğŸ“Œ **Claves SSH**
- **Nombre de clave:** `multi_llm_poc`
- **MÃ©todo:** AutenticaciÃ³n con clave pÃºblica

### ğŸ“Œ **ConfiguraciÃ³n de Red**
- **VPC:** `Default`
- **Subred:** `Predeterminada (asignaciÃ³n automÃ¡tica de IP)`
- **Grupo de seguridad:** 
  - Permitir **SSH (Puerto 22) desde cualquier IP** `0.0.0.0/0`
  - Permitir **HTTPS (Puerto 443)**

> âš  **Importante:** Se recomienda restringir el acceso SSH solo a direcciones IP de confianza.

---

## **4ï¸âƒ£ ConfiguraciÃ³n de Almacenamiento**
- **Volumen raÃ­z:** `100 GiB (gp3)`
  - **IOPS:** `3000`
  - **Throughput:** `125 MB/s`
- **Cifrado:** No habilitado (opcional para producciÃ³n)

---

## **5ï¸âƒ£ ConfiguraciÃ³n Avanzada**
### ğŸ“Œ **ConfiguraciÃ³n de CPU**
- **Uso de GPU:** `Habilitado`
- **Uso de CPU optimizado:** `AutomÃ¡tico`

### ğŸ“Œ **ConfiguraciÃ³n de Metadatos**
- **ProtecciÃ³n IMDSv2:** `Habilitado`
- **LÃ­mite de llamadas:** `Predeterminado`

---

## **6ï¸âƒ£ Script de InicializaciÃ³n (User Data)**
El siguiente **script de User Data** se ejecutarÃ¡ al iniciar la instancia, asegurando la configuraciÃ³n automÃ¡tica de entorno.

```bash
#!/bin/bash

# Redirigir salida estÃ¡ndar y errores a un log
exec > /var/log/user-data.log 2>&1

echo "----------------------------"
echo "ğŸš€ INICIO DE CONFIGURACIÃ“N ğŸš€"
echo "----------------------------"

# Variables del entorno
DEEPSEEK_PATH="/opt/deepseek"
DOCKER_COMPOSE_VERSION="1.29.2"

echo "ğŸ“Œ Actualizando el sistema..."
apt update && apt upgrade -y

echo "ğŸ“Œ Instalando paquetes esenciales..."
apt install -y python3 python3-pip docker.io unzip wget git curl nvidia-utils-535

# Verificar si Docker ya estÃ¡ instalado
if ! command -v docker &> /dev/null; then
    echo "ğŸ“Œ Instalando Docker..."
    apt install -y docker.io
    systemctl enable docker
    systemctl start docker
    usermod -aG docker ubuntu
else
    echo "âœ… Docker ya estÃ¡ instalado."
fi

# Verificar si NVIDIA estÃ¡ funcionando correctamente
echo "ğŸ“Œ Verificando estado de la GPU..."
if nvidia-smi &> /dev/null; then
    echo "âœ… NVIDIA detectada correctamente."
else
    echo "âŒ ERROR: No se detectÃ³ NVIDIA. Verifica los drivers."
    exit 1
fi

# Instalar NVIDIA-Docker
echo "ğŸ“Œ Instalando NVIDIA-Docker..."
distribution=$(. /etc/os-release;echo $ID$VERSION_ID) && \
wget -qO - https://nvidia.github.io/nvidia-docker/gpgkey | apt-key add - && \
wget -qO - https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | tee /etc/apt/sources.list.d/nvidia-docker.list && \
apt update && apt install -y nvidia-docker2 && systemctl restart docker

# Verificar que NVIDIA-Docker funcione correctamente
if docker run --rm --gpus all nvidia/cuda:11.6.2-base-ubuntu20.04 nvidia-smi &> /dev/null; then
    echo "âœ… NVIDIA-Docker funcionando correctamente."
else
    echo "âŒ ERROR: NVIDIA-Docker no funciona. Revisa la configuraciÃ³n."
    exit 1
fi

# Instalar Docker Compose
echo "ğŸ“Œ Instalando Docker Compose..."
if ! command -v docker-compose &> /dev/null; then
    curl -L "https://github.com/docker/compose/releases/download/${DOCKER_COMPOSE_VERSION}/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
    chmod +x /usr/local/bin/docker-compose
    echo "âœ… Docker Compose instalado correctamente."
else
    echo "âœ… Docker Compose ya estÃ¡ instalado."
fi

# Descargar e instalar DeepSeek
if [ ! -d "$DEEPSEEK_PATH" ]; then
    echo "ğŸ“Œ Descargando DeepSeek..."
    git clone https://github.com/DeepSeek-AI/DeepSeek-LLM.git "$DEEPSEEK_PATH"
    cd "$DEEPSEEK_PATH" || exit 1
    pip3 install -r requirements.txt
    echo "âœ… DeepSeek instalado en $DEEPSEEK_PATH."
else
    echo "âœ… DeepSeek ya estÃ¡ instalado."
fi

# Configurar acceso SSH y logs bÃ¡sicos
echo "ğŸ“Œ Configurando SSH..."
systemctl enable ssh
systemctl start ssh

echo "ğŸ“Œ Creando log de inicio..."
echo "Instancia inicializada correctamente" > /var/log/deepseek-setup.log

echo "----------------------------"
echo "ğŸ¯ CONFIGURACIÃ“N FINALIZADA ğŸ¯"
echo "----------------------------"
```

---

## **7ï¸âƒ£ Resumen Final**
- **Instancia:** `g4dn.xlarge`
- **GPU:** `NVIDIA T4 (16GB VRAM)`
- **Almacenamiento:** `100 GiB (gp3)`
- **Seguridad:** `SSH habilitado, HTTPS habilitado`
- **ConfiguraciÃ³n automÃ¡tica:** `User Data con Docker, NVIDIA y DeepSeek`
- **Costo estimado:** `$0.526 USD/hora (On-Demand)`

---

## **8ï¸âƒ£ Recomendaciones Adicionales**
âœ… **Usar instancias Spot** para reducir costos hasta un **70%**.  
âœ… **Monitorear GPU y CPU** con `nvidia-smi` y `htop`.  
âœ… **Restringir el acceso SSH** a una IP especÃ­fica para mayor seguridad.  

---

## **9ï¸âƒ£ Comandos Ãštiles**
Una vez desplegada la instancia, usa los siguientes comandos para verificar la configuraciÃ³n:

### **ğŸ“Œ Verificar estado de la GPU**
```bash
nvidia-smi

### **ğŸ“Œ Verificar que Docker estÃ¡ corriendo**
```bash
systemctl status docker
```

### **ğŸ“Œ Revisar logs del script de inicializaciÃ³n (User Data)**
```bash
cat /var/log/user-data.log
```

### **ğŸ“Œ Revisar logs especÃ­ficos de la configuraciÃ³n de DeepSeek**
```bash
cat /var/log/deepseek-setup.log
```

### **ğŸ“Œ Conectar a la instancia vÃ­a SSH**
```bash
ssh -i multi_llm_poc.pem ubuntu@<IP_PUBLICA>
```

** âš  Nota: Reemplaza <IP_PUBLICA> con la direcciÃ³n IP de la instancia en AWS.**

---

## ** Proximos Pasos**

1. âœ… Configurar entorno virtual para DeepSeek
```bash
cd /opt/deepseek
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

2. âœ… Ejecutar pruebas con el modelo DeepSeek
```bash
python deepseek_test.py
```

3. âœ… Configurar alertas en AWS CloudWatch para monitoreo de uso de GPU y CPU.

---

## **ğŸ“Œ ConclusiÃ³n**
Con esta configuraciÃ³n, la instancia AWS EC2 estÃ¡ lista para ejecutar **DeepSeek LLM** con **soporte para GPU NVIDIA y Docker**, asegurando un entorno optimizado para pruebas de IA.

ğŸš€ **Â¡Todo listo para desplegar modelos de Deep Learning en la nube!**

---

## **ğŸ“Œ Referencias y Recursos**
- ğŸ“„ [DocumentaciÃ³n Oficial de AWS EC2](https://docs.aws.amazon.com/ec2/)
- ğŸ“„ [GuÃ­a de NVIDIA Docker](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)
- ğŸ“„ [Repositorio Oficial de DeepSeek-AI](https://github.com/DeepSeek-AI/DeepSeek-LLM)

---

## **ğŸ“Œ Contacto y Soporte**
Si necesitas asistencia adicional:
- ğŸ“§ Contacto: `tuemail@ejemplo.com`
- ğŸ›  Foro de AWS: [AWS Forums](https://forums.aws.amazon.com/)
- ğŸ’¬ Comunidad de Deep Learning: [Deep Learning Discord](https://discord.gg/deep-learning)

---

## **ğŸ“Œ Notas Finales**
âœ… **Recuerda** cerrar la instancia cuando no la estÃ©s utilizando para evitar costos innecesarios.  
âœ… **Para futuras mejoras**, considera probar instancias mÃ¡s potentes como `g5.xlarge` si el modelo requiere mÃ¡s VRAM.  
âœ… **Explora CloudWatch** para monitorear el rendimiento y establecer alertas en caso de uso excesivo de GPU o CPU.

ğŸ“Œ **Ãšltima actualizaciÃ³n:** _$(date)_  

---

âœ **Autor:** _Fabio Salinas_  
ğŸ“… **Fecha de CreaciÃ³n:** _2025-02-22_  
ğŸ¢ **Proyecto:** _Multi LLM_
